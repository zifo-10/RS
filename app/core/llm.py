from typing import Optional

from openai import OpenAI
from pydantic import Field


class LLMResponse:
    answer: str = Field(description="The response generated by the LLM model.")
    item_id: Optional[str] = Field(description="The ID of the item in the database.")


class LLM:
    def __init__(self, api_key: str):
        self.llm_client = OpenAI(api_key=api_key)

    def generate_response(self, system: str, user: str):
        response = self.llm_client.chat.completions.create(
            model="gpt-4",
            messages=[
                {"role": "system", "content": system},
                {"role": "user", "content": user},
            ],
            temperature=0,
            stream=True,
        )
        for chunk in response:
            yield chunk.model_dump()["choices"][0]["delta"]["content"]
